{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                        gitpython \\\n",
    "                                        magika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"heroic-rain-298320\"  # @param {type:\"string\"}\n",
    "# LOCATION = \"europe-west3-a\"  # @param {type:\"string\"}\n",
    "LOCATION = \"europe-west1\"\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from vertexai.generative_models import (\n",
    "    FunctionDeclaration,\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GitHub repository URL\n",
    "repo_url = \"https://github.com/assafelovic/gpt-researcher\"  # @param {type:\"string\"}\n",
    "\n",
    "# The location to clone the repo\n",
    "repo_dir = \"./repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import git\n",
    "import magika\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import fnmatch\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "m = magika.Magika()\n",
    "\n",
    "\n",
    "def clone_repo(repo_url, repo_dir):\n",
    "    \"\"\"Clone a GitHub repository.\"\"\"\n",
    "\n",
    "    if os.path.exists(repo_dir):\n",
    "        shutil.rmtree(repo_dir)\n",
    "    os.makedirs(repo_dir)\n",
    "    git.Repo.clone_from(repo_url, repo_dir)\n",
    "\n",
    "\n",
    "def download_latest_snapshot(repo_url, repo_dir):\n",
    "    \"\"\"Download the latest snapshot of a GitHub repository.\"\"\"\n",
    "\n",
    "    # Derive the URL for downloading the zip file\n",
    "    if repo_url.endswith('/'):\n",
    "        repo_url = repo_url[:-1]\n",
    "    zip_url = repo_url + '/archive/refs/heads/master.zip'  # Adjust branch if necessary\n",
    "\n",
    "    # Ensure the target directory exists\n",
    "    if os.path.exists(repo_dir):\n",
    "        shutil.rmtree(repo_dir)\n",
    "    os.makedirs(repo_dir)\n",
    "\n",
    "    # Download and extract the repository's zip file\n",
    "    print('Downloading from url:', zip_url)\n",
    "    response = requests.get(zip_url)\n",
    "    if response.status_code == 200:\n",
    "        with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "            zip_ref.extractall(repo_dir)\n",
    "    else:\n",
    "        raise Exception('Failed to download the repository snapshot.')\n",
    "\n",
    "\n",
    "def extract_code(repo_dir, exclude_patterns=[\"*poetry.lock\"]):\n",
    "    \"\"\"Create an index, extract content of code/text files, excluding specific files.\"\"\"\n",
    "    \n",
    "    code_index = []\n",
    "    code_text = \"\"\n",
    "    for root, _, files in os.walk(repo_dir):\n",
    "        for file in files:\n",
    "            if any(fnmatch.fnmatch(file, pattern) for pattern in exclude_patterns):\n",
    "                continue  # Skip files matching any of the exclude patterns\n",
    "\n",
    "            file_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(file_path, repo_dir)\n",
    "            code_index.append(relative_path)\n",
    "\n",
    "            file_type = m.identify_path(Path(file_path))\n",
    "            if file_type.output.group in (\"text\", \"code\"):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as f:\n",
    "                        code_text += f\"----- File: {relative_path} -----\\n\"\n",
    "                        code_text += f.read()\n",
    "                        code_text += \"\\n-------------------------\\n\"\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    return code_index, code_text\n",
    "\n",
    "\n",
    "def get_github_issue(owner: str, repo: str, issue_number: str) -> str:\n",
    "    headers = {\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "        \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
    "    }  # Set headers for GitHub API\n",
    "\n",
    "    # Construct API URL\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/issues/{issue_number}\"\n",
    "\n",
    "    try:\n",
    "        response_git = requests.get(url, headers=headers)\n",
    "        response_git.raise_for_status()  # Check for HTTP errors\n",
    "    except requests.exceptions.RequestException as error:\n",
    "        print(f\"Error fetching issue: {error}\")  # Handle potential errors\n",
    "\n",
    "    issue_data = response_git.json()\n",
    "    if issue_data:\n",
    "        return issue_data[\"body\"]\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def save_text_to_file(text: str, filename: str):\n",
    "    \"\"\"Save the given text to a file in the current working directory.\"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(filename, \"w\") as file:\n",
    "            file.write(text)\n",
    "        print(f\"Text successfully saved to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while saving text to {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "download_latest_snapshot(repo_url, repo_dir)\n",
    "\n",
    "code_index, code_text = extract_code(repo_dir, exclude_patterns=[\"*.log\", \"*.lock\", \".*\"])\n",
    "\n",
    "save_text_to_file(code_text, \"code_text\")\n",
    "save_text_to_file(json.dumps(code_index), \"code_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-1.5-pro-preview-0514\"  # @param {type:\"string\"}\n",
    "\n",
    "model = GenerativeModel(\n",
    "    MODEL_ID,\n",
    "    system_instruction=[\n",
    "        \"You are a coding expert.\",\n",
    "        \"Your mission is to answer all code related questions with given context and instructions.\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_prompt(question):\n",
    "    \"\"\"Generates a prompt to a code related question.\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Questions: {question}\n",
    "\n",
    "    Context:\n",
    "    - The entire codebase is provided below.\n",
    "    - Here is an index of all of the files in the codebase:\n",
    "      \\n\\n{code_index}\\n\\n.\n",
    "    - Then each of the files is concatenated together. You will find all of the code you need:\n",
    "      \\n\\n{code_text}\\n\\n\n",
    "\n",
    "    Answer:\n",
    "  \"\"\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"\"\"\n",
    "#   Give me a summary of this codebase, and tell me the top 3 things that I can learn from it.\n",
    "# \"\"\"\n",
    "question = \"\"\"\n",
    "  Provide a getting started guide to onboard new developers to the codebase.\n",
    "\"\"\"\n",
    "\n",
    "prompt = get_code_prompt(question)\n",
    "contents = [prompt]\n",
    "\n",
    "# Generate text using non-streaming method\n",
    "response = model.generate_content(contents)\n",
    "\n",
    "# Print generated text and usage metadata\n",
    "print(f\"\\nAnswer:\\n{response.text}\")\n",
    "print(f'\\nUsage metadata:\\n{response.to_dict().get(\"usage_metadata\")}')\n",
    "print(f\"\\nFinish reason:\\n{response.candidates[0].finish_reason}\")\n",
    "print(f\"\\nSafety settings:\\n{response.candidates[0].safety_ratings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "  Provide a getting started guide to onboard new developers to the codebase.\n",
    "\"\"\"\n",
    "\n",
    "prompt = get_code_prompt(question)\n",
    "contents = [prompt]\n",
    "\n",
    "responses = model.generate_content(contents, stream=True)\n",
    "for response in responses:\n",
    "    IPython.display.Markdown(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
